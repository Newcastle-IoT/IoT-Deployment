##################################################################################################################
##																												##
## Spark master for running Spark in a standalone mode. Run the following commands to build the image and       ##
## run the master container. These the master is intended to be run as service on a Swarm mode cluster.	      	##
##																			  									##
## $docker build -t <image name> --rm <location of this file>													##
##															  													##
## $docker service create --name master --network <your overlay net> --replicas 1 -p 8080:8080 -p 7077:7077 	##
## -p 4040:4040 --env MAIN=<main method class> --env URL=<http://<location to spark program JAR file>           ##
## <image name> <nodes public DNSs>   																			##
##	  	                                            															##
##################################################################################################################

FROM alisu/java:latest
MAINTAINER Saleh Mohamed <s.mohamed@nclf.ac.uk>

LABEL "hadoop.version"="2.7.1", "spark.version"="2.0.0"
ENV home /user 
WORKDIR ${home}
ADD scripts/master-config.sh ${home}
RUN mkdir Downloads

## Downloading and installing hadoop
RUN wget http://apache.mirrors.tds.net/hadoop/common/hadoop-2.7.1/hadoop-2.7.1.tar.gz -P Downloads
RUN tar zxvf Downloads/hadoop-* -C /usr/local
RUN mv /usr/local/hadoop-* /usr/local/hadoop
ENV JAVA_HOME=/usr
ENV PATH $PATH:$JAVA_HOME/bin
ENV HADOOP_HOME /usr/local/hadoop
ENV PATH $PATH:$HADOOP_HOME/bin
ENV HADOOP_CONF_DIR /usr/local/hadoop/etc/hadoop
RUN chown -R root $HADOOP_HOME

## Installing Scala
RUN apt-get update -y
RUN apt-get install scala -y

## Download and install Sparks
RUN wget http://d3kbcqa49mib13.cloudfront.net/spark-2.0.0-bin-hadoop2.7.tgz -P Downloads
RUN tar zxvf Downloads/spark-* -C /usr/local
RUN mv /usr/local/spark-* /usr/local/spark
ENV SPARK_HOME /usr/local/spark
ENV PATH $PATH:$SPARK_HOME/bin
ENV PATH $PATH:$SPARK_HOME/sbin
RUN chown -R root $SPARK_HOME
RUN cp $SPARK_HOME/conf/spark-env.sh.template $SPARK_HOME/conf/spark-env.sh
RUN echo "export JAVA_HOME=/usr" | tee -a $SPARK_HOME/conf/spark-env.sh
RUN echo "export SPARK_WORKER_CORES=6" | tee -a $SPARK_HOME/conf/spark-env.sh
RUN touch $SPARK_HOME/conf/slaves

EXPOSE 8080
EXPOSE 8081
EXPOSE 4040
EXPOSE 7077
EXPOSE 6066
EXPOSE 1883
ENTRYPOINT ["/bin/bash", "master-config.sh"]

